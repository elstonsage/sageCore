#include <fstream>
#include "segreg/analysis.h"
#include "segreg/segreg_calculator.h"
#include "segreg/analysis_out.h"
#include "segreg/iterative_models.h"

namespace SAGE
{

namespace SEGREG
{

double primary_analysis::like_cutoff = numeric_limits<double>::quiet_NaN();

inline bool primary_analysis::eval_model_bad(const eval_model_ptr& e)
{
  return e->is_bad;
}

inline bool primary_analysis::model_less_than 
    (const eval_model_ptr& l, const eval_model_ptr& r)
{
  double lhs_val = l->current_results.getFinalFunctionValue();
  double rhs_val = r->current_results.getFinalFunctionValue();
      
  return lhs_val < rhs_val;
}

//lint --e{713} There are many conversions from signed to unsigned and back
//lint --e{732} here, but they're all ok, and due to maxfun (which we don't
//              want to change right now) using signed values, while vectors
//              use unsigned values.

#define LIKELIHOOD_DISTANCE 1
#define FINAL_LIKELIHOOD_DISTANCE 0.001

//=================================
// primary_analysis
//=================================

//--------------------------------------------------------------------------
//
//	run_analysis(...)
//
//--------------------------------------------------------------------------

// due to JA
bool primary_analysis::check_all_fixed(const PedigreeDataSet& ped_data, const model& test_model)
{ 

  my_models.resize(1);
  my_models[0] = eval_model_ptr(new evaluation_model(test_model, ped_data));

  return (my_models[0]->params.allfixed());
}

// 

vector<std::pair<string,double> > primary_analysis::do_single_evaluation \
(const PedigreeDataSet& ped_data, const model& test_model, double& func_value, vector<string>& par_type) 
{ // due to JA

   out.messages() << " No independent parameters to maximize. Likelihood will be evaluated  " << endl;
   out.messages() << " at user specified values of parameters and results written to the .sum file. " << endl;
   vector<model> ms;
   ms.clear();
   ms.push_back(test_model);

   construct_models(ped_data, ms);

   std::pair<double, int> ret;
  
   ret = MAXFUN::Maximizer::evaluateOnce(my_models[0]->params, my_models[0]->calculator);

   std::pair<string,double> current_pair;
   vector< std::pair<string,double> > param_value_pair_vec;
   param_value_pair_vec.clear();
   par_type.clear(); 
   
   my_models[0]->current_results.setFinalFunctionValue(ret.first); // assigning the value of the likelihood
   
   func_value = my_models[0]->current_results.getFinalFunctionValue();

   for(SAGE::MAXFUN::ParameterIterator paramit = my_models[0]->params.getParamBegin(); \
         paramit != my_models[0]->params.getParamEnd();\
          paramit++){
      current_pair.first = paramit->getName();
      current_pair.second = paramit->getCurrentEstimate();
      param_value_pair_vec.push_back(current_pair);
      par_type.push_back(MAXFUN::ParamTypeEnum2str(paramit->getInitialType()));
    }

  if(my_models[0]->mdl.get_type_prob()) {
    my_models[0]->calculator.calculate_post_geno_probs(my_results.my_type_probs);
    string file = test_model.get_file_name_root() + ".typ"; 
    ofstream o(file.c_str());

    o << "#! Type Probability File, version 1.1." << endl
      << "#  This file is automatically generated.  Do not edit!" << endl << endl;

    o << "Model=\"" << file << "\",title=\"" << test_model.get_title() << "\"" << endl;
    o << "{" << endl;

    // Print out the allele frequencies

    o << "  alleles" << endl
      << "  {" << endl;

    o << "    A = " << test_model.freq_sub_model.freq_A() << endl;
    o << "    B = " << (1 - test_model.freq_sub_model.freq_A()) << endl;

    pg::dump_post_genos(o,my_results.my_type_probs);

    o << "  }" << endl;
   }
    return param_value_pair_vec;
}


const primary_analysis_results& primary_analysis::run_analysis
(const PedigreeDataSet& ped_data, const model_vector& ms, bool user_defined)

{

  //cout<<"===================================="<<endl;
  //cout<<"Now I am doing run_analysis!"<<endl;
  //cout<<"===================================="<<endl;

  // Clear the results object in preparation for the analysis
  my_results = primary_analysis_results();
  
  // Check to see if there's any models at all.  If there aren't, we return
  // produce and error and return.  This should never happen.
  if(ms.empty())
  {
    return my_results;
  }

  // Set the results object to the first of our model vector elements.  This
  // sets all the model criteria for producing output, should there be an error.
  // If everything is successful, this model will be overwritten.
  my_results.my_model = ms[0];

  // Construct our model spaces

  construct_models(ped_data, ms);

  // Test them

  if(!test_models(ped_data, user_defined))
  {
    return my_results;
  }

  primary_type pt = my_models[0]->mdl.get_primary_trait_type();

  // Initialize Penalization - calculate c_value

  double c_value = 1.0;
                
  if(pt == pt_CONTINUOUS)
    c_value = get_initial_penalization(ped_data);
  
  // Set c_value

  for(size_t i = 0; i != my_models.size(); ++i)
  {
    my_models[i]->calculator.set_continuous_penalty_component(c_value);
  }       

  // Run our analyses --

  run_initial_maxfun();

  reduce_model_set();

  run_final_maxfun();  // We always want to finalize at least once

  // If continuous, we need may need to maximize again.

/*
  -- Removed on 2004-01-15 because penalizations don't currently work.  See
     SCR #855 for more information.

  if(pt == pt_CONTINUOUS)
  {
     double Beta_max = get_beta_max();
     
     while( c_value < Beta_max )
     {
         c_value = 2 * Beta_max;

         // Set c_value

         for(size_t i = 0; i != my_models.size(); ++i)
         {
           my_models[i]->c.set_continuous_penalty_component(c_value);
         }

         run_final_maxfun();

         Beta_max = get_beta_max();
     }
  }
*/

  finalize_model();

  // Construct the results object:

  my_results.my_valid                    = true;

  my_results.my_ped_data          = ped_data;
  my_results.my_model             = my_models[0]->mdl;
  my_results.my_maxfun_results    = my_models[0]->current_results;
  my_results.my_subpedigree_count = my_models[0]->calculator.get_subpedigree_count();
  my_results.my_unconnected_count = my_models[0]->calculator.get_unconnected_count();


  // If we need any of the special entries, generate them.

  if(my_models[0]->mdl.get_type_prob())
    my_models[0]->calculator.calculate_post_geno_probs(my_results.my_type_probs);

  if(my_models[0]->mdl.get_pen_func_output())
    my_models[0]->calculator.calculate_pen_func_probs(my_results.my_pfunc_probs);

  if(my_models[0]->mdl.get_model_class() == model_MLM)
    my_models[0]->calculator.calculate_mlm_resid_corr(my_results.my_mlm_resid_corr);

// due to JA, storing these results for future use
    if (my_results.my_valid) {
     Iterative_Models::intermax.push_back(my_results);
    }

  return my_results;
}
//--------------------------------------------------------------------------
//      
//      get_initial_penalization(...)
//
//--------------------------------------------------------------------------
double primary_analysis::get_initial_penalization(const PedigreeDataSet& ped_data) const
{
//  cout<<"===================================="<<endl;
//  cout<<"Now I am doing get_initial_penalization!"<<endl;
//  cout<<"===================================="<<endl;

  // Penalization - calculate c_value for continuous case

  double Yi;
  double c_value = NEGATIVE_INF;

  string trait_name   = my_models[0]->mdl.get_primary_trait();
      
  size_t trait_number = ped_data.get_raw_data()->info().trait_find(trait_name);

  for(size_t i = 0; i != my_models.size(); ++i)
  {
     for(FPED::PedigreeConstIterator ped  = ped_data.get_raw_data()->pedigree_begin();
             ped != ped_data.get_raw_data()->pedigree_end(); ++ped)
     {  
       for(FPED::MemberConstIterator ind = ped->member_begin();
               ind!= ped->member_end(); ++ind)
       {
          Yi      = ped->info().trait(ind->index(),trait_number);

          my_models[i]->mdl.transf_sub_model.transform(Yi);

          c_value = max(c_value, Yi);
       }
     }
  }

  return c_value;
}
//--------------------------------------------------------------------------
//      
//      get_Beta_max(... )
//
//--------------------------------------------------------------------------
double primary_analysis::get_beta_max() const
{
//  cout<<"===================================="<<endl;
//  cout<<"Now I am doing get_beta_max!"<<endl;
//  cout<<"===================================="<<endl;
 
  // calculate max(Beta_u)

  double Beta1, Beta2, Beta3, Beta_max;

  for(size_t i = 0; i != my_models.size(); ++i)
  {
     Beta1 = my_models[i]->mdl.type_dependent_sub_model().parameter(index_AA);
     Beta2 = my_models[i]->mdl.type_dependent_sub_model().parameter(index_AB);
     Beta3 = my_models[i]->mdl.type_dependent_sub_model().parameter(index_BB);

     Beta_max = max(Beta_max, Beta1);
     Beta_max = max(Beta_max, Beta2);
     Beta_max = max(Beta_max, Beta3);
  }
  return Beta_max;    
} 

//--------------------------------------------------------------------------
//
//	run_continuous_final_maxfun(...)
//
//--------------------------------------------------------------------------
/*
void primary_analysis::run_continuous_final_maxfun()
{

}

//--------------------------------------------------------------------------
//
//	run_discrete_final_maxfun(...)
//
//--------------------------------------------------------------------------

void primary_analysis::run_discrete_final_maxfun()
{

}  
*/
//--------------------------------------------------------------------------
//
//	evaluation_model(...)
//
//--------------------------------------------------------------------------

primary_analysis::evaluation_model::evaluation_model
    (const model& mv, const PedigreeDataSet& ped_data)
  : mdl(mv), params(), calculator(ped_data,mdl), current_results(), is_bad(false)
{
  //cout<<"===================================="<<endl;
  //cout<<"Now I am doing evaluation_model!"<<endl;
  //cout<<"===================================="<<endl;
  
  primary_type pt = mdl.get_primary_trait_type();

  // The models here are added or not added based on a logical ordering
  // which is primarily based on the manual ordering of sub-blocks. 
  // However, we have moved the covariates up to be with the appropriate
  // element to allow more easy tracking

  if(pt == pt_CONTINUOUS || pt == pt_ONSET)
  {
    params.addSubModel(&mdl.comp_trait_sub_model);

    params.addSubModel(&mdl.mean_sub_model      );
    params.addSubModel(&mdl.mean_cov_sub_model  );

    params.addSubModel(&mdl.var_sub_model       );
    params.addSubModel(&mdl.var_cov_sub_model   );
  }

  if(pt == pt_BINARY || pt == pt_ONSET)
  {
    params.addSubModel(&mdl.susc_sub_model      );
    params.addSubModel(&mdl.susc_cov_sub_model  );
  }

  if(mdl.get_model_class() == model_FPMM)
  {
    params.addSubModel(&mdl.fpmm_sub_model      );
  }
  else
  {
    params.addSubModel(&mdl.resid_sub_model     );
  }

  if(pt == pt_CONTINUOUS || pt == pt_ONSET)
  {
    params.addSubModel(&mdl.transf_sub_model    );
  }

  params.addSubModel(&mdl.freq_sub_model        );

  params.addSubModel(&mdl.transm_sub_model      );

  if(pt == pt_BINARY || pt == pt_ONSET)
  {
    params.addSubModel(&mdl.prev_sub_model      );
  }
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

void primary_analysis::construct_models
      (const PedigreeDataSet& ped_data,
       const model_vector&    mv)
{
  my_models.resize(mv.size());

//  FPED::RefMultiPedigree& rmp = const_cast<FPED::RefMultiPedigree&>(my_ped_data.get_data());

  for(size_t i = 0; i != mv.size(); ++i)
  {
    my_models[i] = eval_model_ptr(new evaluation_model(mv[i], ped_data));
  }
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

bool primary_analysis::test_models(const PedigreeDataSet& ped_data,
                                   bool user_defined)
{
  user_defined = user_defined || out.get_debug_status();

  for(uint i = 0; i != my_models.size(); ++i)
  {
    if(my_models.size() > 1)
      out.messages() << "        Testing Initial Value " << setw(2) << (i+1)
                     << ".............................." << flush;
    else
      out.messages() << "        Testing model........................................." << flush;

    segreg_errors::error_code return_value = segreg_errors::EVAL_OK;

    // Calculate our thresholds.  If we can't calculate ascertainment
    // thresholds, then we can't do anything.  If we can, we can
    // test the model
    string trait = my_models[i]->mdl.get_primary_trait();

    size_t trait_number = ped_data.get_raw_data()->info().trait_find(trait);

    if(out.get_debug_status())
    {
      MAXFUN::ParameterMgr& params = my_models[i]->params;

      out.debug() << "Initial Values:" << endl; 

      out.debug() << "             Parameter           Init.Est." << endl
                  << "             ==============      ==========" << endl;
      for(int x = 0; x < params.getParamCount(); ++x)
        out.debug() << setw(10) << x << ":  " << setw(20) << params.getParameter(x).getName() 
                    << setw(10) << doub2str(params.getParameter(x).getInitialEstimate(),20)  << endl;
    }

    if(!my_models[i]->mdl.ascer_sub_model.calculate_thresholds(*ped_data.get_raw_data(),trait_number))
      return_value = segreg_errors::BAD_THRESHOLDS;
    else
      return_value = test_model(i);

    // If there was a problem, we remove the model
    if(return_value != segreg_errors::EVAL_OK)
    {
      if(!user_defined)
      {
        out.messages() << "...Done." << endl;
      }
      else
      {
        out.messages() << "...Error." << endl << endl;

        // Produce an error message about the model
        //lint -e{788}
        switch(return_value)
        {
          case segreg_errors::MCC_FAILED_TRANSFORM :
            errors << priority(error) << "Unable to transform data as "
                   << "specified.  Please check initial values, if specified, "
                   << "and/or for outliers and try again." <<endl;
            break;

          case segreg_errors::MCC_VARIANCE_INVALID :
            errors << priority(error) << "Bad initial variance calculated. "
                   << "Please set the variance higher for initial values."
                   << endl;
            break;

          case segreg_errors::BAD_INIT_PARAM :
          {
            errors << priority(error) << "Initial parameters include variables (";

            // Print out comma delimited list of parameters that are invalid.
            MAXFUN::ParameterMgr& params = my_models[i]->params;

            bool l = false;

            for(int j = 0; j < params.getParamCount(); ++j)
            {
              double d = params.getParameter(j).getInitialEstimate();

              if(!finite(d))
              {
                if(l)
                  errors << ", ";
                else
                  l = true;

                errors << params.getParameter(j).getName();
              }
            }

            errors << ") that are invalid.  "
                   << "Check your parameter file for missing variables."
                   << endl;
          }

            break;
          case segreg_errors::ZERO_LIKELIHOOD :
            errors << priority(error) << "Initial Evaluation returns 0. "
                   << "Cannot proceed." << endl;
            break;

          case segreg_errors::BAD_LIKELIHOOD :
            errors << priority(error) << "Initial Evaluation returns a non-number. "
                   << "Cannot Proceed." << endl;
            break;

          case segreg_errors::BAD_LEX_VALUE :
            errors << priority(error) << "Maxfun returned an error code on startup. "
                   << "Cannot Proceed." << endl;
            break;

          case segreg_errors::BAD_THRESHOLDS :
            errors << priority(error) << "Unable to calculate initial thresholds "
                   << "for ascertainment.  Please check your parameter file."
                   << endl;
            break;

          case segreg_errors::MLM_CORR_BOUNDARY :
            errors << priority(error) << "Initial correlation outside of "
                   << "calculated bounds.  Please check your parameter file."
                   << endl;
            break;

          default:
            break;
        }
      }

      my_models[i]->is_bad = true;
    }
    else
      out.messages() << "...Done." << endl;
  }

  // Remove Null models

  size_t orig_model_count = my_models.size();

  //lint -e{534}
  my_models.erase(remove_if(my_models.begin(), my_models.end(), 
      eval_model_bad), my_models.end());

  // Check to make sure there are still models available

  if(my_models.empty())
  {
    errors << priority(error) << "Unable to find valid initial starting states.  "
           << "Model cannot be maximized.  Check for outliers and/or reduce "
           << "the number of parameters to be estimated.  Note that in the "
           << "model class MLM it may not be possible to fix any of the familial "
           << "correlations/associations."
           << endl;

    return false;
  }
  else if(my_models.size() != orig_model_count)
  {
    out.messages() << "        Keeping "
                   << setw(2) << my_models.size() << " of "
                   << setw(2) << orig_model_count << " initial models"
                   << "..........................Done." << endl;
  }

  return true;
}

/** Returns:
 *
 *   enum error_code { EVAL_OK = 0,
 *                      MCC_FAILED_TRANSFORM,
 *                      MCC_VARIANCE_INVALID,
 *                      BAD_INIT_PARAM,
 *                      ZERO_LIKELIHOOD,
 *                      BAD_LIKELIHOOD,
 *                      BAD_LEX_VALUE
 *                    }
 */
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

segreg_errors::error_code
primary_analysis::test_model(uint m)
{
  std::pair<double, int> ret;
  
  ret = MAXFUN::Maximizer::evaluateOnce(my_models[m]->params, my_models[m]->calculator);

  if(ret.second) return (segreg_errors::error_code) ret.second;

  if(!finite(ret.first)) return segreg_errors::BAD_LIKELIHOOD;

  return segreg_errors::EVAL_OK;
}

//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

void
primary_analysis::run_initial_maxfun()
{
//  cout<<"===================================="<<endl;
//  cout<<"Now I am doing run_initial_maxfun()!"<<endl;
//  cout<<"===================================="<<endl;

  for(uint i = 0; i < my_models.size(); ++i)
  {
    if(my_models.size() > 1)
      out.messages() << "        Attempting Initial Value " << setw(2) << (i+1) 
                     << "..........................." << flush;
    else
      out.messages() << "        Performing Maximization..............................." << flush;

    run_initial_maxfun(i);

    out.messages() << "...Done." << endl;

    // Debugging output.
    
    MAXFUN::ParameterMgr& params = my_models[i]->params;

    out.debug() << "Final likelihood after first maximization loop: "
                << my_models[i]->current_results.getFinalFunctionValue(); 

    out.debug() << "             Parameter           Init.Est.   Final Est." << endl
               << "             ==============      ==========  ==========" << endl;

    for(int j = 0; j < params.getParamCount(); ++j)
    {
      const MAXFUN::Parameter& param = params.getParameter(j);
      out.debug() << setw(10) << j << ":  " << setw(20) << right << param.getName() 
           << setw(10) << doub2str(param.getInitialEstimate(),20)  << "  " 
           << setw(10) << doub2str(param.getFinalEstimate(),20) << endl;
    }
  }
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

void
primary_analysis::run_initial_maxfun(uint mdl)
{
  // Set up the methods to be used

  MAXFUN::SequenceCfg sequence(MAXFUN::SequenceCfg::USER_DEFINED);
  
  sequence.addRunCfg(MAXFUN::RunCfg::DIRECT_WITHOUT, 1);
  sequence.getLatestRunCfg().epsilon1 = my_quality ? 1e-3  : 1e-2;
  sequence.getLatestRunCfg().epsilon2 = my_quality ? 1e-12 : 1e-8;
//  sequence.getLatestRunCfg().epsilon2 = my_quality ? 1e-10 : 1e-8;
  
  sequence.addRunCfg(MAXFUN::RunCfg::VAR_METRIC_IDENTITY, 20);
  sequence.getLatestRunCfg().epsilon1       = my_quality ? 1e-3 : 1e-2;
  sequence.getLatestRunCfg().epsilon2       = my_quality ? 1e-12 : 1e-8;
//  sequence.getLatestRunCfg().epsilon2       = my_quality ? 1e-10 : 1e-8;
  sequence.getLatestRunCfg().control_option = MAXFUN::RunCfg::PREVIOUS_NONCONVERGENCE;
  sequence.getLatestRunCfg().var_cov        = MAXFUN::RunCfg::FINAL;
  
  sequence.addRunCfg(MAXFUN::RunCfg::DIRECT_WITHOUT, my_quality ? 50 : 20);
  sequence.getLatestRunCfg().epsilon1       = my_quality ? 1e-4 : 1e-3;
  sequence.getLatestRunCfg().epsilon2       = my_quality ? 1e-12 : 1e-8;
//  sequence.getLatestRunCfg().epsilon2       = my_quality ? 1e-10 : 1e-8;
  sequence.getLatestRunCfg().control_option = MAXFUN::RunCfg::PREVIOUS_NONCONVERGENCE;

  // Run the analysis

  my_models[mdl]->current_results = 
       MAXFUN::Maximizer::Maximize(sequence, my_models[mdl]->params,
                                             my_models[mdl]->calculator,
                                             my_models[mdl]->mdl.my_maxfun_debug);
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

void primary_analysis::reduce_model_set()
{
  
  // Should be invariant
  assert(!my_models.empty());

  // If there is only one model, we know it's the best one

  if(my_models.size() == 1) return;

  out.messages() << "      Choosing models to finalize..." << flush;

  // Find the maximum likelihood of all remaining models

  eval_model_vector::iterator max_model =
      max_element(my_models.begin(), my_models.end(), model_less_than);

  double max_log_likelihood = (*max_model)->current_results.getFinalFunctionValue();

  // Remove those models that aren't close enough.

  double cutoff = max_log_likelihood - LIKELIHOOD_DISTANCE;

  // This is slightly complex.  We use the fails_cutoff functor to choose
  // which elements to keep. Anything which returns true is removed from the
  // vector through remove_if and erase.

  //lint -e{534}
  my_models.erase(remove_if(my_models.begin(), my_models.end(),
      fails_cutoff(cutoff)), my_models.end());

  assert(!my_models.empty());

  out.messages() << "(keeping " << setw(2) << my_models.size()
      << ").................Done." << endl;
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

void
primary_analysis::run_final_maxfun()
{

  for(size_t i = 0; i < my_models.size(); ++i)
  {
    if(my_models.size() > 1)
      out.messages() << "        Finalizing Model " << setw(2) << (i+1) 
           << "..................................." << flush;
    else
      out.messages() << "        Finalizing Model......................................" << flush;

    run_final_maxfun(i);

    out.messages() << "...Done." << endl;

    // Debugging output.
    
    MAXFUN::ParameterMgr& params = my_models[i]->params;

    out.debug() << "Final likelihood: "
                << my_models[i]->current_results.getFinalFunctionValue(); 

    out.debug() << "             Parameter           Init.Est.   Final Est." << endl
               << "             ==============      ==========  ==========" << endl;

    for(int j = 0; j < params.getParamCount(); ++j)
    {
      const MAXFUN::Parameter& param = params.getParameter(j);
      out.debug() << setw(10) << j << ":  " << setw(20) << right << param.getName() 
           << setw(10) << doub2str(param.getInitialEstimate(),20)  << "  " 
           << setw(10) << doub2str(param.getFinalEstimate(),20) << endl;
    }
  }
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

void primary_analysis::run_final_maxfun(uint m)
{
  MAXFUN::ParameterMgr& params = my_models[m]->params;
  
  // Store the initial estimates

  vector<double> initial_estimates(params.getParamCount());
  for(int j = 0; j < params.getParamCount(); ++j)
    initial_estimates[j] = params.getParameter(j).getInitialEstimate();

  // Set up the method to be used for finalizing.  This is based upon the
  // 'optimum' maximization scheme worked out by Dr. Elston and others.
  //
  // Depending on the quality of the run, the maximization parameters are
  // slightly different.

  MAXFUN::SequenceCfg sequence(MAXFUN::SequenceCfg::USER_DEFINED);

  sequence.addRunCfg(MAXFUN::RunCfg::VAR_METRIC_ESTIMATE, my_quality ? 20 : 10);
  sequence.getLatestRunCfg().epsilon1       = my_quality ? 1e-12 : 1e-3;
  sequence.getLatestRunCfg().epsilon2       = my_quality ? 1e-12 : 1e-9;
  sequence.getLatestRunCfg().var_cov        = MAXFUN::RunCfg::FINAL;

  for(int j = 0; j < params.getParamCount(); ++j)
  {
    MAXFUN::Parameter& p = params.getParameter(j);
    p.setInitialEstimate(p.getFinalEstimate());
  }

  // Run the analysis

  my_models[m]->current_results = 
      MAXFUN::Maximizer::Maximize(sequence, my_models[m]->params,
                                            my_models[m]->calculator,
                                            my_models[m]->mdl.my_maxfun_debug);

#if 0
  printf("\nFinal values:\n");

  for(int j = 0; j < maxfun.nt(); ++j)
    printf("  theta %2i=%f\tV=%12.10f\tSE=%f\tG=%f\n",  j, 
              maxfun.param(j), maxfun.av(j,j), maxfun.stde(j), maxfun.g(j));
#endif

  // restore the initial estimates

  for(int j = 0; j < params.getParamCount(); ++j)
  {
    MAXFUN::Parameter& p = params.getParameter(j);
    p.setInitialEstimate(initial_estimates[j]);
  }
}
//--------------------------------------------------------------------------
//
//
//
//--------------------------------------------------------------------------

/// To finalize our model, we want a model within .001 of the best
/// likelihood which also has standard errors (if any of the models
/// do).
///
/// To do this, we take several passes.  On the first, we eliminate all
/// models more than .001 from our best model.  Second, we determine if any
/// of the reamining models have standard errors and if so, remove all that
/// don't.  Finally, we find the best model of any that remain (there should
/// always be at least one) and throw out all the others.
void
primary_analysis::finalize_model()
{

  // Invariant condition
  assert(!my_models.empty());

  if(my_models.size() == 1) return;

  out.messages() << "      Choosing Final Estimates................................" << flush;

  // Find the maximum likelihood of all models

  eval_model_vector::iterator max_model =
      max_element(my_models.begin(), my_models.end(), model_less_than);

  double max_log_likelihood = (*max_model)->current_results.getFinalFunctionValue();

  // Remove those models that aren't close enough.

  double cutoff = max_log_likelihood - FINAL_LIKELIHOOD_DISTANCE;

  // This is slightly complex.  We use the fails_cutoff functor to choose
  // which elements to keep. Anything which returns true is removed from the
  // vector through remove_if and erase.

  //lint -e{534}
  my_models.erase(remove_if(my_models.begin(), my_models.end(),
      fails_cutoff(cutoff)), my_models.end());

  // At this point, we have removed all models more than
  // FINAL_LIKELIHOOD_DISTANCE from the best value.
  //
  // What we now want is the best model with standard errors.  So first, we
  // eliminate everything without standard errors if something with standard
  // errors exists.

  // Determine if there are models with standard errors
  if(find_if(my_models.begin(), my_models.end(), has_std_err()) != my_models.end())
  {
    // If there are models with standard errors, remove all models without

    my_models.erase(remove_if(my_models.begin(), my_models.end(),
        not1(has_std_err())), my_models.end());
  }

  // At this point, all the models left are within a certain distance of the
  // best likelihood, and all either have standard errors or none do.

  // Find the maximum likelihood of all remaining models

  max_model = max_element(my_models.begin(), my_models.end(), model_less_than);

  // Should never happen
  assert(max_model != my_models.end());

  // Move the best to the front and erase everything else.

  my_models[0] = *max_model;

  //lint -e{534}
  my_models.erase(my_models.begin()+1, my_models.end());

  // If no models left, then we've got a problem.  Should never happen
  assert(!my_models.empty());

  out.messages() << "...Done." << endl;
}

double primary_analysis_results::get_one_mean_results()
{
//
// due to JA, retrieving the value of a single mean 
// after maximization 
//
    double returnval = QNAN;

    const MAXFUN::ParameterMgr& thismgr = get_maxfun_results().getParameterMgr();
    
       for (int i = 0; i != thismgr.getParamCount(); ++i) {
        if (!(SAGE::isnan(returnval))) break;
        const MAXFUN::Parameter& param = thismgr.getParameter(i); 
        
        if ((param.getName().substr(0,4) == "mean") \
           && (param.getName().substr(0,5) != "mean_")) returnval = param.getFinalEstimate();
      }
   
      return returnval;
}

double primary_analysis_results::get_one_susc_results()
{
//
// due to JA, retrieving the value of a single mean 
// after maximization 
//
    double returnval = QNAN;

    const MAXFUN::ParameterMgr& thismgr = get_maxfun_results().getParameterMgr();
    
       for (int i = 0; i != thismgr.getParamCount(); ++i) {
        if (!(SAGE::isnan(returnval))) break;
        const MAXFUN::Parameter& param = thismgr.getParameter(i); 
        
        if ((param.getName().substr(0,4) == "susc") \
           && (param.getName().substr(0,5) != "susc_")) returnval = param.getFinalEstimate();
      }
   
      return returnval;
}

} // End segreg ns

} // End SAGE ns
